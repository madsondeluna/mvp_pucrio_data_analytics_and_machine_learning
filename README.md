
# MVP II - Machine Learning & Analytics (40530010056_20250_01)

**Curso:** Data Science & Analytics ‚Äì PUC-Rio

**Autor:** Madson Arag√£o

---

![Python](https://img.shields.io/badge/python-3670A0?style=for-the-badge&logo=python&logoColor=ffdd54) ![NumPy](https://img.shields.io/badge/numpy-%23013243.svg?style=for-the-badge&logo=numpy&logoColor=white) ![Pandas](https://img.shields.io/badge/pandas-%23150458.svg?style=for-the-badge&logo=pandas&logoColor=white) ![Matplotlib](https://img.shields.io/badge/Matplotlib-%23ffffff.svg?style=for-the-badge&logo=Matplotlib&logoColor=black) ![scikit-learn](https://img.shields.io/badge/scikit--learn-%23F7931E.svg?style=for-the-badge&logo=scikit-learn&logoColor=white) ![GitHub](https://img.shields.io/badge/github-%23121011.svg?style=for-the-badge&logo=github&logoColor=white)![Google Colab](https://img.shields.io/badge/Google%20Colab-%23F9A825.svg?style=for-the-badge&logo=googlecolab&logoColor=white) 

---


#### üü° [Acesse o notebook no Google Colab](https://colab.research.google.com/drive/1--VBTH2w0f66WHhe33Wdgm40o6nHTX__?usp=sharing)

#### ‚ö™Ô∏è [Acesse o notebook no GitHub](https://github.com/madsondeluna/mvp_pucrio_data_analytics_and_machine_learning/blob/main/mvp_pucrio_data_analytics.ipynb)

#### üîµ [Dataset](https://github.com/madsondeluna/mvp_pucrio_data_analytics_and_machine_learning/blob/main/data/data.csv) 

#### üü¢ [Modelos salvos a partir deste estudo](https://github.com/madsondeluna/mvp_pucrio_data_analytics_and_machine_learning/tree/main/modelos-pre-treinados)


## Vis√£o Geral do Projeto

Este projeto tem como objetivo principal validar a viabilidade de classificar dados extra√≠dos de c√©lulas mam√°rias em processos de altera√ß√£o celular (benignas vs. malignas) utilizando t√©cnicas cl√°ssicas de an√°lise de dados em Python e preparar o dataset para modelos de Machine Learning. Exploramos a relev√¢ncia biol√≥gica das vari√°veis, avaliamos o potencial diagn√≥stico dos modelos e comparamos o desempenho de diferentes algoritmos de classifica√ß√£o.

## II. Contexto e Import√¢ncia da Base de Dados

Utilizamos o **Breast Cancer Wisconsin (Diagnostic) Data Set**, dispon√≠vel no UCI Machine Learning Repository. Esta base cont√©m **569 amostras** de tumores mam√°rios, rotuladas como **benigno (B)** ou **maligno (M)**, e **30 vari√°veis num√©ricas** que descrevem caracter√≠sticas morfol√≥gicas dos n√∫cleos celulares, extra√≠das de imagens digitalizadas.

A import√¢ncia desta base de dados reside no seu potencial para:

- **Diagn√≥stico precoce:** Auxiliar radiologistas na identifica√ß√£o r√°pida de tumores malignos.
- **Padroniza√ß√£o de laudos:** Reduzir a subjetividade na avalia√ß√£o humana.
- **Suporte √† pesquisa cl√≠nica:** Correlacionar caracter√≠sticas de imagem com resultados terap√™uticos.

As vari√°veis incluem medidas de raio, textura, per√≠metro, √°rea, suavidade, compacidade, concavidade, pontos c√¥ncavos, simetria e dimens√£o fractal, capturadas em tr√™s escalas: m√©dia (`_mean`), erro-padr√£o (`_se`), e "pior" valor (`_worst`). Altera√ß√µes nestas caracter√≠sticas s√£o biologicamente relevantes para diferenciar c√©lulas benignas de malignas.

## III. Explora√ß√£o e Pr√©-processamento dos Dados

Antes de modelar, realizamos as seguintes etapas:

1.  **Carregamento e Sele√ß√£o:** Importamos os dados diretamente de um reposit√≥rio GitHub para reprodutibilidade. Removemos colunas irrelevantes (`id`, `Unnamed: 32`).
2.  **An√°lise Explorat√≥ria Visual:**
    *   Verificamos a distribui√ß√£o das classes (357 benignos, 212 malignos), observando um leve desbalanceamento.
    *   Utilizamos mapas de calor para analisar a correla√ß√£o entre as vari√°veis, identificando alta multicolinearidade entre alguns atributos (ex: `radius_mean`, `perimeter_mean`, `area_mean`).
    *   Plotagens de violino e pairplots foram usadas para visualizar a distribui√ß√£o das vari√°veis por classe e identificar atributos com bom poder discriminat√≥rio (`area_mean`, `concave points_mean`, etc.).
3.  **Tratamento da Multicolinearidade:** Removemos vari√°veis altamente correlacionadas (com |r| >= 0.9) para simplificar o modelo e evitar problemas em algoritmos sens√≠veis a isso. Foram removidos `radius_mean`, `perimeter_mean`, `concavity_mean`, `radius_se`, `perimeter_se`, `radius_worst`, `perimeter_worst`.
4.  **Padroniza√ß√£o:** Aplicamos `StandardScaler()` para normalizar as vari√°veis num√©ricas, garantindo que todas as features contribuam igualmente em algoritmos baseados em dist√¢ncia ou gradiente.
5.  **Divis√£o Treino/Teste:** Separamos os dados em 75% para treino e 25% para teste (`random_state=10` para reprodutibilidade), garantindo que a distribui√ß√£o das classes fosse preservada nesta divis√£o.

## IV. Modelagem e Avalia√ß√£o

Este √© um problema de **classifica√ß√£o supervisionada bin√°ria**. Treinamos e avaliamos quatro modelos de classifica√ß√£o populares:

-   **K-Nearest Neighbors (KNN)**
-   **Random Forest (RF)**
-   **Support Vector Machine (SVM)**
-   **XGBoost**

Utilizamos **valida√ß√£o cruzada (10 folds)** no conjunto de treino para uma avalia√ß√£o robusta do desempenho do modelo durante a fase de treinamento e sele√ß√£o de hiperpar√¢metros (no caso do KNN, a valida√ß√£o cruzada foi usada para selecionar o melhor `k=7`). As m√©tricas finais foram calculadas no conjunto de **teste padronizado**.

### M√©tricas de Avalia√ß√£o

Avaliamos os modelos com as seguintes m√©tricas:

-   **Acur√°cia:** Propor√ß√£o de classifica√ß√µes corretas.
-   **MCC (Matthews Correlation Coefficient):** Medida robusta de correla√ß√£o entre a predi√ß√£o e o valor real, √∫til em classes desbalanceadas.
-   **AUC-ROC:** √Årea sob a curva Receiver Operating Characteristic, indica a capacidade do modelo de discriminar entre as classes.
-   **Matriz de Confus√£o:** Apresenta True Positives (VP), True Negatives (VN), False Positives (FP) e False Negatives (FN). Em diagn√≥stico m√©dico, minimizar FN (classificar maligno como benigno) √© crucial.
-   **Precis√£o (Precision):** Propor√ß√£o de identifica√ß√µes positivas que foram realmente corretas.
-   **Recall (Sensibilidade):** Propor√ß√£o de casos positivos reais que foram corretamente identificados.

### Resultados Comparativos no Conjunto de Teste

| Modelo        | Acur√°cia | MCC    | AUC-ROC | VP | VN | FP | FN | Precis√£o (Benigno) | Recall (Benigno) | Precis√£o (Maligno) | Recall (Maligno) |
|---------------|----------|--------|---------|----|----|----|----|--------------------|------------------|--------------------|------------------|
| KNN           | 0.9580   | 0.9090 | 0.9968  | 48 | 89 | 2  | 4  | 0.9570             | 0.9780           | 0.9600             | 0.9231           |
| Random Forest | 0.9860   | 0.9705 | 0.9987  | 52 | 89 | 2  | 0  | 1.0000             | 0.9780           | 0.9630             | 1.0000           |
| SVM           | 0.9860   | 0.9705 | 1.0000  | 52 | 89 | 2  | 0  | 1.0000             | 0.9780           | 0.9630             | 1.0000           |
| XGBoost       | 0.9720   | 0.9396 | 0.9985  | 50 | 89 | 2  | 2  | 0.9780             | 0.9780           | 0.9615             | 0.9615           |

*As m√©tricas VP, VN, FP, FN referem-se √† classe 'Maligno'.*

## V. Principais Achados e Conclus√µes

A an√°lise comparativa revela que todos os modelos apresentaram alto desempenho na classifica√ß√£o de tumores mam√°rios, com acur√°cia superior a 95% e AUC-ROC acima de 0.99.

-   **Modelos de Destaque:** **Random Forest** e **SVM** se destacaram por atingirem a maior acur√°cia e MCC, e, fundamentalmente, por apresentarem **zero Falsos Negativos (FN = 0)** no conjunto de teste. Isso significa que eles foram capazes de identificar corretamente todos os casos malignos no teste, o que √© um resultado cr√≠tico em aplica√ß√µes m√©dicas. O SVM ainda obteve uma AUC-ROC perfeita (1.0000).
-   **Desempenho Forte:** **XGBoost** tamb√©m demonstrou um desempenho muito robusto, com m√©tricas elevadas e um n√∫mero baixo de Falsos Negativos (FN = 2). √â uma excelente alternativa, especialmente em cen√°rios onde a escalabilidade e a efici√™ncia computacional s√£o importantes.
-   **Modelo Base S√≥lido:** O **KNN**, apesar de ser o modelo com menor desempenho entre os avaliados (FN = 4), ainda assim obteve resultados muito bons, validando a qualidade das features e a abordagem de pr√©-processamento.

A cuidadosa etapa de pr√©-processamento, incluindo a an√°lise de correla√ß√£o e a padroniza√ß√£o, foi essencial para o sucesso de todos os modelos.

## VI. Como Usar o Notebook

Para replicar a an√°lise e os resultados deste projeto, siga os passos abaixo:

1.  **Abrir no Google Colab:** Clique no bot√£o "Open in Colab" no topo deste README (se dispon√≠vel) ou fa√ßa upload do arquivo `.ipynb` para o Google Colab.
2.  **Executar as C√©lulas:** Execute as c√©lulas do notebook sequencialmente, de cima para baixo. Certifique-se de que cada c√©lula seja conclu√≠da antes de passar para a pr√≥xima.
3.  **Acesso aos Dados:** O notebook carrega os dados diretamente do reposit√≥rio GitHub, ent√£o n√£o √© necess√°rio fazer download manual do arquivo CSV.
4.  **Modelos Pr√©-Treinados:** Os modelos treinados (KNN, Random Forest, SVM, XGBoost) s√£o salvos no diret√≥rio `modelos_pre_treinados` ap√≥s a execu√ß√£o da se√ß√£o correspondente. Voc√™ tamb√©m pode baix√°-los diretamente do reposit√≥rio GitHub para uso posterior sem a necessidade de retreinamento.

## VII. Modelos Pr√©-Treinados

Os modelos finais treinados (.pkl) neste notebook foram salvos e est√£o dispon√≠veis para download direto no seguinte diret√≥rio do reposit√≥rio GitHub:

https://github.com/madsondeluna/mvp_pucrio_data_analytics_and_machine_learning/tree/main/modelos-pre-treinados 

Voc√™ pode carregar esses modelos em outro ambiente Python usando a biblioteca `pickle`.


